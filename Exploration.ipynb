{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook examines the two pickles provided by Keunwoo Choi (MSD_id_to_7D_id.pkl and 7D_id_to_path.pkl), as well as a few of the databases provided by the Million Song Dataset (lastfm_similars.db, track_metadata.db, lastfm_tags.db).\n",
    "\n",
    "It then creates three important data structures for the machine learning task:\n",
    "\n",
    "1) a set of valid track_ids, representing the only tracks for which we have song waveform data\n",
    "\n",
    "2) a list of pairs of tracks, along with their similarities, where both tracks in the pair are in {valids}\n",
    "\n",
    "3) a dictionary containing all the metadata for each song in {valids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import sqlite3\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "sys.path.insert(0, './deep-learning-models')\n",
    "import audio_conv_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "msd_to_7d = pickle.load(open('./code-shsd/MSD_id_to_7D_id.pkl', 'rb'))\n",
    "_7d_to_path = pickle.load(open('./code-shsd/7D_id_to_path.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n",
      "999033\n"
     ]
    }
   ],
   "source": [
    "print(len(msd_to_7d))\n",
    "print(len(_7d_to_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lastfm_similars_conn = sqlite3.connect('lastfm_similars.db')\n",
    "lastfm_similars = lastfm_similars_conn.cursor()\n",
    "track_metadata_conn = sqlite3.connect('track_metadata.db')\n",
    "track_metadata = track_metadata_conn.cursor()\n",
    "lastfm_tags_conn = sqlite3.connect('lastfm_tags.db')\n",
    "lastfm_tags = lastfm_tags_conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('similars_dest',), ('similars_dest_tmp',), ('similars_src',)]\n",
      "[('songs',)]\n"
     ]
    }
   ],
   "source": [
    "# list all the tables\n",
    "lastfm_similars.execute(\"SELECT name FROM sqlite_master WHERE type='table' ORDER BY name;\")\n",
    "track_metadata.execute(\"SELECT name FROM sqlite_master WHERE type='table' ORDER BY name;\")\n",
    "lastfm_tags.execute(\"SELECT name FROM sqlite_master WHERE type='table' ORDER BY name;\")\n",
    "lastfm_tables = lastfm_similars.fetchall()\n",
    "track_tables = track_metadata.fetchall()\n",
    "lastfm_tags_tables = lastfm_tags.fetchall()\n",
    "print(lastfm_tables)\n",
    "print(track_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CREATE TABLE similars_src (tid TEXT, target TEXT)',)]\n",
      "[('CREATE TABLE songs (track_id text PRIMARY KEY, title text, song_id text, release text, artist_id text, artist_mbid text, artist_name text, duration real, artist_familiarity real, artist_hotttnesss real, year int, track_7digitalid int, shs_perf int, shs_work int)',)]\n"
     ]
    }
   ],
   "source": [
    "# print the columns of these two tables\n",
    "lastfm_columns = lastfm_similars.execute(\"SELECT sql FROM sqlite_master WHERE tbl_name = 'similars_src' AND type = 'table'\")\n",
    "track_columns = track_metadata.execute(\"SELECT sql FROM sqlite_master WHERE tbl_name = 'songs' AND type = 'table'\")\n",
    "lastfm_tags_columns = lastfm_tags.execute(\"SELECT sql FROM sqlite_master WHERE tbl_name = 'tags' AND type = 'table'\")\n",
    "print(lastfm_columns.fetchall())\n",
    "print(track_columns.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grab all data from one particular table\n",
    "lastfm_data = lastfm_similars.execute(\"SELECT * FROM similars_src\")\n",
    "track_data = track_metadata.execute(\"SELECT * FROM songs\")\n",
    "lastfm_all_tags = lastfm_tags.execute(\"SELECT tag FROM tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TRMMMYQ128F932D901', 'Silent Night', 'SOQMMHC12AB0180CB8', 'Monster Ballads X-Mas', 'ARYZTJS1187B98C555', '357ff05d-848a-44cf-b608-cb34b5701ae5', 'Faster Pussy cat', 252.05506, 0.649822100201, 0.394031892714, 2003, 7032331, -1, 0)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for row in track_data:\n",
    "    print(row)\n",
    "    count +=1\n",
    "    if count > 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/6/8679375.clip.mp3\n",
      "8/4/8416224.clip.mp3\n",
      "6/6/6650421.clip.mp3\n",
      "3/4/3412731.clip.mp3\n",
      "2/3/2392893.clip.mp3\n",
      "8/0/804826.clip.mp3\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "found = 0\n",
    "for row in lastfm_data:\n",
    "    if row[0] in msd_to_7d:\n",
    "        if msd_to_7d[row[0]] in _7d_to_path:\n",
    "            print(_7d_to_path[msd_to_7d[row[0]]])\n",
    "            found += 1\n",
    "    count +=1\n",
    "    if count > 5:\n",
    "        break\n",
    "print(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('classic rock',)\n",
      "('Progressive rock',)\n",
      "('blues',)\n",
      "('memphis slim',)\n",
      "('pop',)\n",
      "('70s',)\n",
      "('Middle of the road',)\n",
      "('Bonjour ca va',)\n",
      "('Tony Levin',)\n",
      "('instrumental',)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for row in lastfm_all_tags:\n",
    "    print(row)\n",
    "    count +=1\n",
    "    if count > 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no duplicates in _7d_to_path\n",
      "number of valid entries in the msd_to_7d dict:  999043\n",
      "assembling track pairs...\n",
      "creating dictionary map...\n",
      "getting all tids...\n",
      "adding song tags to dictionary map...\n",
      "converting all dictionary elements into tuples...\n"
     ]
    }
   ],
   "source": [
    "# generate 3 data structures:\n",
    "# a list of all MSD_ids in the mp3 dataset\n",
    "# a list of track pairs along with their distances, where both songs in the pair are present in the mp3 dataset\n",
    "# a dictionary that maps the valid MSD_ids to (path_name, track_metadata)\n",
    "valids = set()\n",
    "pairs = []\n",
    "msd_to_info = {}\n",
    "tmp = {}\n",
    "count_tmp = defaultdict(int)\n",
    "for k,v in _7d_to_path.items():\n",
    "    count_tmp[k] += 1\n",
    "    tmp[k] = []\n",
    "\n",
    "#sanity check: no duplicates here\n",
    "for k,v in count_tmp.items():\n",
    "    if v > 1:\n",
    "        print(k, v)\n",
    "        break\n",
    "else:\n",
    "    print(\"no duplicates in _7d_to_path\")\n",
    "\n",
    "for k,v in msd_to_7d.items():\n",
    "    if v in tmp:\n",
    "        tmp[v].append(k)\n",
    "        valids.add(k)\n",
    "\n",
    "# there are duplicates in msd_to_7d, however\n",
    "duplicates = []\n",
    "for k,v in tmp.items():\n",
    "    if len(v) > 1:\n",
    "        duplicates.append((k,v))\n",
    "    \n",
    "print(\"number of valid entries in the msd_to_7d dict: \", len(valids))\n",
    "\n",
    "# now assemble the track pairs\n",
    "print(\"assembling track pairs...\")\n",
    "lastfm_data = lastfm_similars.execute(\"SELECT * FROM similars_src\")\n",
    "for row in lastfm_data:\n",
    "    if row[0] in valids:\n",
    "        song1_id = row[0]\n",
    "        words = row[1].split(',')\n",
    "        n = len(words)\n",
    "        assert n % 2 == 0\n",
    "        for i in range(int(n/2)):\n",
    "            song2_id = words[i*2]\n",
    "            if song2_id in valids:\n",
    "                similarity = words[i*2+1]\n",
    "                pairs.append((song1_id, song2_id, similarity))\n",
    "                \n",
    "# now get the dictionary map\n",
    "print(\"creating dictionary map...\")\n",
    "track_data = track_metadata.execute(\"SELECT * FROM songs\")\n",
    "for row in track_data:\n",
    "    if row[0] in valids:\n",
    "        song_id = row[0]\n",
    "        data = [_7d_to_path[msd_to_7d[row[0]]]]\n",
    "        for elem in row[1:]:\n",
    "            data.append(elem)\n",
    "        msd_to_info[song_id] = data\n",
    "        \n",
    "# get all tids\n",
    "print(\"getting all tids...\")\n",
    "lastfm_all_tracks = lastfm_tags.execute(\"SELECT tid FROM tids\")\n",
    "all_tids = []\n",
    "for row in lastfm_all_tracks:\n",
    "    all_tids.append(row[0])\n",
    "\n",
    "# insert tags into msd_to_info\n",
    "print(\"adding song tags to dictionary map...\")\n",
    "for tid in all_tids:\n",
    "    if tid in valids:\n",
    "        query = \"SELECT tags.tag, tid_tag.val FROM tid_tag, tids, tags WHERE tags.ROWID=tid_tag.tag AND tid_tag.tid=tids.ROWID and tids.tid='%s'\" % tid\n",
    "        res = lastfm_tags.execute(query)\n",
    "        valid_tags = []\n",
    "        for row in res:\n",
    "            if row[0] in audio_conv_utils.TAGS:\n",
    "                valid_tags.append(row)\n",
    "        assert tid in msd_to_info\n",
    "        msd_to_info[tid].append(tuple(valid_tags))\n",
    "    \n",
    "# turn all dictionary elements into immutable tuples\n",
    "print(\"converting all dictionary elements into tuples...\")\n",
    "for k,v in msd_to_info.items():\n",
    "    msd_to_info[k] = tuple(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valids size: 33.554656 mB\n",
      "pairs size: 477.08584 mB\n",
      "msd_to_info size: 50.331744 mB\n"
     ]
    }
   ],
   "source": [
    "print(\"valids size:\", sys.getsizeof(valids)/1000000, \"mB\")\n",
    "print(\"pairs size:\", sys.getsizeof(pairs)/1000000, \"mB\")\n",
    "print(\"msd_to_info size:\", sys.getsizeof(msd_to_info)/1000000, \"mB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to pickles\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(valids, open(\"valids.pkl\", \"wb\"))\n",
    "pickle.dump(pairs, open(\"pairs.pkl\", \"wb\"))\n",
    "pickle.dump(msd_to_info, open(\"msd_to_info.pkl\", \"wb\"))\n",
    "print(\"saved to pickles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
